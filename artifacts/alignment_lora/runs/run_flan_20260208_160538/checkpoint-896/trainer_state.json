{
  "best_metric": 3.180379867553711,
  "best_model_checkpoint": "/Users/shubhankartiwari/indian-desi-llm-inference/artifacts/alignment_lora/runs/run_flan_20260208_160538/checkpoint-896",
  "epoch": 3.986651835372636,
  "eval_steps": 500,
  "global_step": 896,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11,
      "grad_norm": 0.26871535181999207,
      "learning_rate": 1.1111111111111113e-05,
      "loss": 3.6687,
      "step": 25
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.2760576903820038,
      "learning_rate": 1.9882491186839016e-05,
      "loss": 3.6269,
      "step": 50
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.27842769026756287,
      "learning_rate": 1.929494712103408e-05,
      "loss": 3.6426,
      "step": 75
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.29874810576438904,
      "learning_rate": 1.870740305522914e-05,
      "loss": 3.6112,
      "step": 100
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2274174690246582,
      "learning_rate": 1.8119858989424208e-05,
      "loss": 3.6436,
      "step": 125
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.38543039560317993,
      "learning_rate": 1.7532314923619274e-05,
      "loss": 3.5203,
      "step": 150
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3725488483905792,
      "learning_rate": 1.6944770857814337e-05,
      "loss": 3.5944,
      "step": 175
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.3606351315975189,
      "learning_rate": 1.6357226792009403e-05,
      "loss": 3.533,
      "step": 200
    },
    {
      "epoch": 1.0,
      "eval_loss": 3.3513312339782715,
      "eval_runtime": 5.0337,
      "eval_samples_per_second": 39.733,
      "eval_steps_per_second": 9.933,
      "step": 224
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.3611011803150177,
      "learning_rate": 1.5769682726204466e-05,
      "loss": 3.5889,
      "step": 225
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.5241656303405762,
      "learning_rate": 1.5182138660399531e-05,
      "loss": 3.491,
      "step": 250
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.37538376450538635,
      "learning_rate": 1.4594594594594596e-05,
      "loss": 3.5949,
      "step": 275
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.42674142122268677,
      "learning_rate": 1.400705052878966e-05,
      "loss": 3.531,
      "step": 300
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5164392590522766,
      "learning_rate": 1.3419506462984727e-05,
      "loss": 3.4938,
      "step": 325
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.4125034809112549,
      "learning_rate": 1.283196239717979e-05,
      "loss": 3.5218,
      "step": 350
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.3823802173137665,
      "learning_rate": 1.2244418331374854e-05,
      "loss": 3.4288,
      "step": 375
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.48670998215675354,
      "learning_rate": 1.165687426556992e-05,
      "loss": 3.4569,
      "step": 400
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.4792512357234955,
      "learning_rate": 1.1069330199764983e-05,
      "loss": 3.4685,
      "step": 425
    },
    {
      "epoch": 2.0,
      "eval_loss": 3.2532403469085693,
      "eval_runtime": 4.9265,
      "eval_samples_per_second": 40.596,
      "eval_steps_per_second": 10.149,
      "step": 449
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.3423449695110321,
      "learning_rate": 1.0481786133960048e-05,
      "loss": 3.5911,
      "step": 450
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.34773266315460205,
      "learning_rate": 9.894242068155113e-06,
      "loss": 3.443,
      "step": 475
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.46848374605178833,
      "learning_rate": 9.306698002350177e-06,
      "loss": 3.449,
      "step": 500
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.39649131894111633,
      "learning_rate": 8.719153936545242e-06,
      "loss": 3.4743,
      "step": 525
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.3928695023059845,
      "learning_rate": 8.131609870740305e-06,
      "loss": 3.4452,
      "step": 550
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.34726980328559875,
      "learning_rate": 7.544065804935371e-06,
      "loss": 3.3042,
      "step": 575
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.3808436393737793,
      "learning_rate": 6.956521739130435e-06,
      "loss": 3.5368,
      "step": 600
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.4570973813533783,
      "learning_rate": 6.3689776733255005e-06,
      "loss": 3.47,
      "step": 625
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.38140106201171875,
      "learning_rate": 5.781433607520564e-06,
      "loss": 3.4273,
      "step": 650
    },
    {
      "epoch": 3.0,
      "eval_loss": 3.1974434852600098,
      "eval_runtime": 4.9154,
      "eval_samples_per_second": 40.688,
      "eval_steps_per_second": 10.172,
      "step": 674
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.4036727249622345,
      "learning_rate": 5.193889541715629e-06,
      "loss": 3.3404,
      "step": 675
    },
    {
      "epoch": 3.11,
      "grad_norm": 0.4267582595348358,
      "learning_rate": 4.6063454759106936e-06,
      "loss": 3.3423,
      "step": 700
    },
    {
      "epoch": 3.23,
      "grad_norm": 0.40414705872535706,
      "learning_rate": 4.018801410105758e-06,
      "loss": 3.3047,
      "step": 725
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.4186302423477173,
      "learning_rate": 3.431257344300823e-06,
      "loss": 3.3617,
      "step": 750
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.37016552686691284,
      "learning_rate": 2.8437132784958875e-06,
      "loss": 3.3958,
      "step": 775
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.41497915983200073,
      "learning_rate": 2.256169212690952e-06,
      "loss": 3.4747,
      "step": 800
    },
    {
      "epoch": 3.67,
      "grad_norm": 0.4025071859359741,
      "learning_rate": 1.6686251468860165e-06,
      "loss": 3.4292,
      "step": 825
    },
    {
      "epoch": 3.78,
      "grad_norm": 0.445022314786911,
      "learning_rate": 1.0810810810810812e-06,
      "loss": 3.357,
      "step": 850
    },
    {
      "epoch": 3.89,
      "grad_norm": 0.4245568811893463,
      "learning_rate": 4.935370152761457e-07,
      "loss": 3.4922,
      "step": 875
    },
    {
      "epoch": 3.99,
      "eval_loss": 3.180379867553711,
      "eval_runtime": 4.9368,
      "eval_samples_per_second": 40.512,
      "eval_steps_per_second": 10.128,
      "step": 896
    }
  ],
  "logging_steps": 25,
  "max_steps": 896,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "total_flos": 334869654405120.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
